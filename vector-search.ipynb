{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import TextLoader # converts raw text (book description) and convert it to format that longchain can work with\n",
    "from langchain.text_splitter import CharacterTextSplitter # splits whole document containing all of the descriptions into meaningful chunks (individual desc of each book)\n",
    "# from langchain_openai import OpenAIEmbeddings # converting chunks into document embeddings\n",
    "from langchain_chroma import Chroma # storing embeddings in vector database ChromaDB\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ],
   "id": "a03a7c6443e0d1e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv(\"data/books_cleaned.csv\", encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "\n",
    "books[\"tagged_description\"] = books[\"tagged_description\"].str.replace('\"', '', regex=False)\n",
    "print(books['tagged_description'].head())"
   ],
   "id": "16351c90587849fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "books",
   "id": "28d29e3b3a2f2732",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "books[\"tagged_description\"]",
   "id": "4c95ca8fb67af062",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "books['tagged_description'].to_csv(\"data/tagged_description.txt\", sep='\\n', index=False)",
   "id": "3417add045ee9919",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "raw_documents = TextLoader('data/tagged_description.txt', encoding='utf-8').load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=0, chunk_overlap=0, separator=\"\\n\") #prioritise splitting on the separator rather than on chunksize\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ],
   "id": "9f97d0486c55c39f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "documents[2]",
   "id": "d628efe8410e724",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Number of documents: {len(documents)}\")\n",
    "print(f\"Average document length: {sum(len(doc.page_content) for doc in documents)/len(documents)} characters\")\n"
   ],
   "id": "8b1a036af9ce48f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "print(\"Model loaded\")"
   ],
   "id": "eba45c60691187d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "class MySTEmbeddings(Embeddings):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return self.model.encode(texts, show_progress_bar=True).tolist()\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.model.encode([text])[0].tolist()\n",
    "\n",
    "my_embeddings = MySTEmbeddings(model)"
   ],
   "id": "e18f97803c28a08d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "import pickle\n",
    "\n",
    "docs = documents\n",
    "\n",
    "batch_size = 500\n",
    "db_faiss = None\n",
    "all_docs = []\n",
    "\n",
    "for i in range(0, len(docs), batch_size):\n",
    "    batch = docs[i:i + batch_size]\n",
    "    all_docs.extend(batch)\n",
    "\n",
    "    if db_faiss is None:\n",
    "        db_faiss = FAISS.from_documents(batch, embedding=my_embeddings)\n",
    "        print(f\"Created FAISS base with batch {i}–{i + len(batch)}\")\n",
    "    else:\n",
    "        db_faiss.add_documents(batch)\n",
    "        print(f\"Added batch {i}–{i + len(batch)}\")\n",
    "\n",
    "db_faiss.save_local(\"faiss_index\")\n",
    "with open(\"data/faiss_docs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_docs, f)\n",
    "\n",
    "print(\"FAISS index and documents saved\")"
   ],
   "id": "db0ac2f242ef001f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = 'A book to teach children about nature'\n",
    "docs = db_faiss.similarity_search(query, k=10)\n",
    "docs"
   ],
   "id": "249b56ded435f9aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "books[books[\"isbn13\"] == int(docs[0].page_content.split()[0].strip())]",
   "id": "ca3354bf90a296cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def retrieve_semantic_recomendations(query: str, top_k: int = 10) -> pd.DataFrame:\n",
    "    recs = db_faiss.similarity_search(query, k=50)\n",
    "\n",
    "    books_list = []\n",
    "\n",
    "    for i in range(0, len(recs)):\n",
    "      books_list.append(int(recs[i].page_content.strip('\"').split()[0]))\n",
    "\n",
    "    return books[books[\"isbn13\"].isin(books_list)].head(top_k)"
   ],
   "id": "e174fbcfbf8258e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "retrieve_semantic_recomendations('A book about space adventure and universe')",
   "id": "d1d5a6a0d907e84a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 9
}
